# USF BIOS - Production Docker Image
# Copyright (c) US Inc. All rights reserved.
#
# BUILD ORDER (FAIL FAST):
# 1. Stage 0: Verify usf_bios package can be built and imported (FAIL IMMEDIATELY if not)
# 2. Stage 1: Build frontend
# 3. Stage 2: Compile Python to .so files
# 4. Stage 3: Production image with proper usf_bios installation

# ============================================================================
# Stage 0: USF BIOS Package Verification (FAIL FAST)
# This stage runs FIRST to verify usf_bios can be built before wasting time
# ============================================================================
FROM python:3.11-slim AS usf-bios-verifier

WORKDIR /verify

# Install minimal build dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    gcc \
    python3-dev \
    git \
    && rm -rf /var/lib/apt/lists/*

# Copy usf_bios package files FIRST
COPY setup.py setup.cfg MANIFEST.in /verify/
COPY requirements.txt /verify/requirements.txt
COPY requirements/ /verify/requirements/
COPY usf_bios/ /verify/usf_bios/

# ============================================================================
# CRITICAL: Install and verify usf_bios package - FAIL BUILD IF THIS FAILS
# ============================================================================
RUN echo "" && \
    echo "============================================================" && \
    echo "  USF BIOS - PACKAGE VERIFICATION (FAIL FAST)" && \
    echo "============================================================" && \
    echo ""

# Step 1: Install framework requirements
RUN echo "[1/4] Installing framework requirements..." && \
    pip install --no-cache-dir -r /verify/requirements/framework.txt && \
    echo "  ✓ Framework requirements installed"

# Step 2: Install usf_bios package
RUN echo "[2/4] Installing usf_bios package..." && \
    cd /verify && pip install --no-cache-dir -e . && \
    echo "  ✓ usf_bios package installed"

# Step 3: Verify usf_bios can be imported (catches missing dependencies)
RUN echo "[3/4] Verifying usf_bios import..." && \
    python -c "import usf_bios; print('  ✓ usf_bios module imported successfully')" && \
    python -c "from usf_bios.utils.torch_utils import get_device; print('  ✓ usf_bios.utils imported successfully')" && \
    python -c "from usf_bios.cli.main import ROUTE_MAPPING; print('  ✓ usf_bios.cli imported successfully')"

# Step 4: Verify CLI entry point exists
RUN echo "[4/4] Verifying CLI entry point..." && \
    which usf_bios && \
    usf_bios --help > /dev/null 2>&1 || echo "  ⚠ CLI help not available (expected in compiled mode)" && \
    echo "  ✓ usf_bios CLI entry point registered"

RUN echo "" && \
    echo "============================================================" && \
    echo "  ✓ USF BIOS VERIFICATION PASSED - Continuing build..." && \
    echo "============================================================" && \
    echo ""

# ============================================================================
# Stage 1: Frontend Builder
# ============================================================================
FROM node:20-alpine AS frontend-builder

WORKDIR /build/frontend
COPY web/frontend/package*.json ./
RUN npm ci
COPY web/frontend/ ./
RUN npm run build

# ============================================================================
# Stage 2: Python Compiler - Compile to native .so files using Cython
# ============================================================================
FROM python:3.11-slim AS python-compiler

WORKDIR /compile

# Install build tools and Cython
RUN apt-get update && apt-get install -y --no-install-recommends \
    gcc \
    python3-dev \
    && rm -rf /var/lib/apt/lists/*

RUN pip install --no-cache-dir cython setuptools

# Copy compilation script first (changes here invalidate cache)
COPY scripts/compile_to_so.py /compile/compile_to_so.py

# Copy Python source
COPY usf_bios/ /compile/usf_bios/
COPY web/backend/ /compile/web/backend/

# Run the Cython compilation (converts .py to native .so files)
RUN python /compile/compile_to_so.py

# Clean up build artifacts
RUN find /compile -name "*.pyc" -delete && \
    find /compile -name "__pycache__" -type d -exec rm -rf {} + 2>/dev/null || true && \
    find /compile -name "build" -type d -exec rm -rf {} + 2>/dev/null || true && \
    rm -f /compile/compile_to_so.py

# ============================================================================
# Stage 3: Production Image
# ============================================================================
FROM python:3.11-slim

LABEL maintainer="US Inc <support@us.inc>"
LABEL description="USF BIOS - Enterprise AI Fine-tuning Platform"
LABEL version="1.0.0"

# Security: Create non-root user
RUN groupadd -r usf && useradd -r -g usf usf

# Environment
ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONUNBUFFERED=1
ENV USF_DISABLE_CLI=1
ENV USF_UI_ONLY=1
ENV HOME=/app
ENV PYTHONPATH=/app:/app/web/backend

# ============================================================================
# COMPREHENSIVE CACHE DIRECTORIES for all ML training scenarios:
# - SFT, LoRA, QLoRA, Full Fine-tuning
# - RLHF, PPO, DPO, GRPO, GKD, KTO
# - Pre-training, Continuous Pre-training
# - Multimodal: Vision, Audio, Video, ASR, TTS
# ============================================================================

# HuggingFace ecosystem
ENV HF_HOME=/app/.cache/huggingface
ENV HUGGINGFACE_HUB_CACHE=/app/.cache/huggingface
ENV TRANSFORMERS_CACHE=/app/.cache/huggingface
ENV HF_DATASETS_CACHE=/app/.cache/datasets

# ModelScope (Chinese models)
ENV MODELSCOPE_CACHE=/app/.cache/modelscope

# PyTorch
ENV TORCH_HOME=/app/.cache/torch
ENV TORCH_EXTENSIONS_DIR=/app/.cache/torch_extensions

# Triton (GPU kernels for FlashAttention, etc.)
ENV TRITON_CACHE_DIR=/app/.cache/triton
ENV TRITON_HOME=/app/.cache/triton

# DeepSpeed (distributed training, ZeRO optimization)
ENV DEEPSPEED_CACHE_DIR=/app/.cache/deepspeed

# bitsandbytes (quantization: QLoRA, 4-bit, 8-bit)
# Do NOT set BNB_CUDA_VERSION - let bitsandbytes auto-detect from PyTorch
ENV BITSANDBYTES_NOWELCOME=1

# Numba (JIT compilation for data processing)
ENV NUMBA_CACHE_DIR=/app/.cache/numba

# XFormers (memory-efficient attention)
ENV XFORMERS_CACHE_DIR=/app/.cache/xformers

# Matplotlib (training plots)
ENV MPLCONFIGDIR=/app/.cache/matplotlib

# Fontconfig (fonts for plots)
ENV FONTCONFIG_CACHE=/app/.cache/fontconfig

# Gradio (if used for UI)
ENV GRADIO_TEMP_DIR=/app/.cache/gradio

# Weights & Biases (experiment tracking)
ENV WANDB_DIR=/app/.cache/wandb
ENV WANDB_CACHE_DIR=/app/.cache/wandb

# Ray (distributed training)
ENV RAY_TMPDIR=/app/.cache/ray

# TensorBoard
ENV TENSORBOARD_LOGDIR=/app/data/logs/tensorboard

# Flash Attention compilation
ENV FLASH_ATTENTION_SKIP_CUDA_BUILD=FALSE

# vLLM (inference engine)
ENV VLLM_CACHE_ROOT=/app/.cache/vllm
ENV VLLM_CONFIG_ROOT=/app/.cache/vllm

# SGLang (inference engine)
ENV SGLANG_CACHE_DIR=/app/.cache/sglang

# lmdeploy (inference engine)
ENV LMDEPLOY_CACHE_DIR=/app/.cache/lmdeploy

# CUDA/cuDNN compilation cache
ENV CUDA_CACHE_PATH=/app/.cache/cuda
ENV CUDA_CACHE_MAXSIZE=1073741824

# DeepSpeed Configuration
# Disable JIT compilation of CUDA ops (not needed for inference/basic training)
# This prevents "CUDA_HOME does not exist" errors when DeepSpeed is imported
ENV DS_BUILD_OPS=0
ENV DS_BUILD_AIO=0
ENV DS_BUILD_SPARSE_ATTN=0
ENV DS_BUILD_TRANSFORMER=0
ENV DS_BUILD_TRANSFORMER_INFERENCE=0
ENV DS_BUILD_STOCHASTIC_TRANSFORMER=0
ENV DS_BUILD_UTILS=0
ENV DS_BUILD_FUSED_ADAM=0
ENV DS_BUILD_FUSED_LAMB=0
ENV DS_BUILD_CPU_ADAM=0
ENV DS_BUILD_CPU_LION=0
ENV DS_BUILD_EVOFORMER_ATTN=0
ENV DS_BUILD_RANDOM_LTD=0
ENV DS_BUILD_INFERENCE_CORE_OPS=0
ENV DS_BUILD_CUTLASS_OPS=0
ENV DS_BUILD_RAGGED_DEVICE_OPS=0

# CUDA paths (for when running on GPU nodes with CUDA installed)
ENV CUDA_HOME=/usr/local/cuda
ENV CUDA_ROOT=/usr/local/cuda

# NCCL (distributed communication)
ENV NCCL_DEBUG=WARN
ENV NCCL_ASYNC_ERROR_HANDLING=1

# Compiler caches
ENV CCACHE_DIR=/app/.cache/ccache
ENV XDG_CACHE_HOME=/app/.cache

# Temp directory
ENV TMPDIR=/app/tmp
ENV TEMP=/app/tmp
ENV TMP=/app/tmp

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    curl \
    git \
    nodejs \
    npm \
    && rm -rf /var/lib/apt/lists/* \
    && apt-get clean

# Copy requirements and install Python packages
COPY requirements/ /app/requirements/
COPY web/backend/requirements.txt /app/web/backend/

# ============================================================================
# CRITICAL: Disable DeepSpeed JIT compilation BEFORE pip install
# This prevents DeepSpeed from trying to compile CUDA ops during installation
# (CUDA toolkit is not available in the build image)
# ============================================================================
ENV DS_BUILD_OPS=0
ENV DS_BUILD_AIO=0
ENV DS_BUILD_SPARSE_ATTN=0
ENV DS_BUILD_TRANSFORMER=0
ENV DS_BUILD_TRANSFORMER_INFERENCE=0
ENV DS_BUILD_STOCHASTIC_TRANSFORMER=0
ENV DS_BUILD_UTILS=0
ENV DS_BUILD_FUSED_ADAM=0
ENV DS_BUILD_FUSED_LAMB=0
ENV DS_BUILD_CPU_ADAM=0
ENV DS_BUILD_CPU_LION=0
ENV DS_BUILD_EVOFORMER_ATTN=0
ENV DS_BUILD_INFERENCE_CORE_OPS=0
ENV DS_BUILD_CUTLASS_OPS=0
ENV DS_BUILD_RAGGED_DEVICE_OPS=0

# Install ALL framework requirements (includes json_repair and other dependencies)
# CRITICAL: Install custom transformers fork FIRST (supports usf_omega architecture)
RUN pip install --no-cache-dir git+https://github.com/apt-team-018/transformers.git && \
    pip install --no-cache-dir -r /app/requirements/framework.txt \
    && pip install --no-cache-dir \
    torch>=2.0 \
    deepspeed \
    nvidia-ml-py \
    && pip install --no-cache-dir -r /app/web/backend/requirements.txt

# Copy compiled .so binaries (no source code)
COPY --from=python-compiler /compile/usf_bios/ /app/usf_bios/
COPY --from=python-compiler /compile/web/backend/ /app/web/backend/

# Copy setup files to install usf_bios as a proper package
# IMPORTANT: setup.py requires requirements.txt and README.md
COPY setup.py setup.cfg MANIFEST.in requirements.txt README.md /app/

# ============================================================================
# INSTALL usf_bios as a pip package (registers CLI entry points)
# ============================================================================
RUN echo "" && \
    echo "=== INSTALLING USF BIOS PACKAGE ===" && \
    cd /app && pip install --no-cache-dir -e . && \
    echo "  ✓ usf_bios installed as pip package"

# ============================================================================
# FINAL VERIFICATION: Ensure usf_bios works in production image
# ============================================================================
RUN echo "" && \
    echo "=== FINAL VERIFICATION: USF BIOS ===" && \
    python -c "import usf_bios; print('  ✓ usf_bios import OK')" && \
    python -c "from usf_bios.utils.torch_utils import get_device, get_device_count; print('  ✓ usf_bios.utils OK')" && \
    which usf_bios && echo "  ✓ usf_bios CLI registered" && \
    echo "=== USF BIOS VERIFICATION PASSED ==="

# VERIFICATION: Ensure all critical files exist after Cython compilation
RUN echo "=== VERIFICATION: Checking compiled files ===" && \
    echo "Backend app structure:" && \
    ls -la /app/web/backend/app/ && \
    echo "Models directory:" && \
    ls -la /app/web/backend/app/models/ && \
    echo "Looking for .so files:" && \
    find /app/web/backend -name "*.so" | head -20 && \
    echo "Checking __init__.py files:" && \
    test -f /app/web/backend/app/__init__.py && echo "  ✓ app/__init__.py" && \
    test -f /app/web/backend/app/models/__init__.py && echo "  ✓ app/models/__init__.py" && \
    test -f /app/web/backend/app/api/__init__.py && echo "  ✓ app/api/__init__.py" && \
    test -f /app/web/backend/app/core/__init__.py && echo "  ✓ app/core/__init__.py" && \
    test -f /app/web/backend/app/services/__init__.py && echo "  ✓ app/services/__init__.py" && \
    echo "Checking db_models.py exists (kept as .py - SQLAlchemy ORM):" && \
    test -f /app/web/backend/app/models/db_models.py && echo "  ✓ db_models.py found" && \
    echo "=== BACKEND VERIFICATION PASSED ==="

# Copy frontend build
COPY --from=frontend-builder /build/frontend/.next/standalone /app/web/frontend/
COPY --from=frontend-builder /build/frontend/.next/static /app/web/frontend/.next/static
COPY --from=frontend-builder /build/frontend/public /app/web/frontend/public

# VERIFICATION: Ensure frontend static files exist
RUN echo "=== VERIFICATION: Checking frontend static files ===" && \
    test -f /app/web/frontend/server.js && echo "  ✓ server.js exists" && \
    test -d /app/web/frontend/.next/static && echo "  ✓ .next/static directory exists" && \
    ls -la /app/web/frontend/.next/static/ && \
    test -d /app/web/frontend/.next/static/chunks && echo "  ✓ chunks directory exists" && \
    test -d /app/web/frontend/.next/static/css && echo "  ✓ css directory exists" && \
    find /app/web/frontend/.next/static/css -name "*.css" | head -3 && \
    echo "=== FRONTEND VERIFICATION PASSED ==="

# Copy RSA public key for log encryption (private key stays with US Inc)
COPY keys/usf_bios_public.pem /app/keys/usf_bios_public.pem

# Install cryptography for RSA encryption
RUN pip install --no-cache-dir cryptography

# Copy and setup entrypoint script
COPY web/entrypoint.sh /app/entrypoint.sh
RUN chmod +x /app/entrypoint.sh

# Security: Make source directories read-only (but NOT data dirs)
RUN chmod -R 555 /app/usf_bios /app/web

# ============================================================================
# CREATE ALL DIRECTORIES with proper permissions
# Comprehensive list for all ML training scenarios:
# - Data: uploads, datasets, outputs, checkpoints, logs, models, db
# - HuggingFace: transformers, datasets, hub
# - ModelScope: Chinese models support
# - PyTorch: hub, kernels, extensions
# - Triton: GPU kernels for FlashAttention, fused ops
# - DeepSpeed: distributed training, ZeRO optimization
# - Numba: JIT compilation for data processing
# - XFormers: memory-efficient attention
# - Matplotlib/Fontconfig: training plots
# - Gradio: UI components
# - W&B: experiment tracking
# - Ray: distributed training
# ============================================================================
RUN mkdir -p \
    /app/data/uploads \
    /app/data/datasets \
    /app/data/output \
    /app/data/outputs \
    /app/data/checkpoints \
    /app/data/logs \
    /app/data/logs/tensorboard \
    /app/data/terminal_logs \
    /app/data/encrypted_logs \
    /app/data/models \
    /app/data/db \
    /app/web/backend/data \
    /app/.cache/huggingface \
    /app/.cache/huggingface/hub \
    /app/.cache/huggingface/datasets \
    /app/.cache/datasets \
    /app/.cache/modelscope \
    /app/.cache/torch \
    /app/.cache/torch/hub \
    /app/.cache/torch/kernels \
    /app/.cache/torch_extensions \
    /app/.cache/triton \
    /app/.triton \
    /app/.triton/autotune \
    /app/.triton/cache \
    /app/.cache/deepspeed \
    /app/.deepspeed \
    /app/.cache/numba \
    /app/.cache/xformers \
    /app/.cache/matplotlib \
    /app/.cache/fontconfig \
    /app/.cache/gradio \
    /app/.cache/wandb \
    /app/.cache/ray \
    /app/.cache/ccache \
    /app/.cache/pip \
    /app/.cache/vllm \
    /app/.cache/sglang \
    /app/.cache/lmdeploy \
    /app/.cache/cuda \
    /app/.local \
    /app/.local/share \
    /app/tmp && \
    chown -R usf:usf /app/data /app/web/backend/data /app/web/frontend /app/.cache /app/.triton /app/.deepspeed /app/.local /app/tmp && \
    chmod -R 755 /app/data /app/web/backend/data /app/web/frontend /app/.cache /app/.triton /app/.deepspeed /app/.local /app/tmp

# Switch to non-root user
USER usf

# Expose frontend port only - backend is internal
EXPOSE 3000

# Health check via frontend
HEALTHCHECK --interval=30s --timeout=10s --start-period=10s --retries=3 \
    CMD curl -f http://localhost:3000 || exit 1

# Entry point
ENTRYPOINT ["/app/entrypoint.sh"]
