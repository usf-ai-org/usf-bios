# USF BIOS - GPU-Optimized Docker Build
# Copyright (c) US Inc. All rights reserved.
#
# USE THIS DOCKERFILE ON GPU SERVERS (H200, H100, A100)
# Build time: ~15-20 minutes on H200 (vs 6+ hours on CPU)
#
# BUILD ORDER (FAIL FAST):
# 1. Stage 0: Verify usf_bios package can be built and imported (FAIL IMMEDIATELY if not)
# 2. Stage 1: Build frontend
# 3. Stage 2: Compile Python to .so files
# 4. Stage 3: Production image with FULL GPU CUDA compilation
#
# USAGE:
#   ./scripts/build-docker-gpu.sh 2.0.0

# ============================================================================
# Stage 0: USF BIOS Package Verification (FAIL FAST)
# This stage runs FIRST to verify usf_bios can be built before wasting time
# ============================================================================
FROM python:3.11-slim AS usf-bios-verifier

WORKDIR /verify

# Install minimal build dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    gcc \
    python3-dev \
    git \
    && rm -rf /var/lib/apt/lists/*

# Copy usf_bios package files FIRST
COPY setup.py setup.cfg MANIFEST.in /verify/
COPY requirements.txt /verify/requirements.txt
COPY requirements/ /verify/requirements/
COPY usf_bios/ /verify/usf_bios/

# ============================================================================
# CRITICAL: Install and verify usf_bios package - FAIL BUILD IF THIS FAILS
# ============================================================================
RUN echo "" && \
    echo "============================================================" && \
    echo "  USF BIOS - PACKAGE VERIFICATION (FAIL FAST)" && \
    echo "============================================================" && \
    echo ""

# Step 1: Install framework requirements
RUN echo "[1/4] Installing framework requirements..." && \
    pip install --no-cache-dir -r /verify/requirements/framework.txt && \
    echo "  ✓ Framework requirements installed"

# Step 2: Install usf_bios package
RUN echo "[2/4] Installing usf_bios package..." && \
    cd /verify && pip install --no-cache-dir -e . && \
    echo "  ✓ usf_bios package installed"

# Step 3: Verify usf_bios can be imported (catches missing dependencies)
RUN echo "[3/4] Verifying usf_bios import..." && \
    python -c "import usf_bios; print('  ✓ usf_bios module imported successfully')" && \
    python -c "from usf_bios.utils.torch_utils import get_device; print('  ✓ usf_bios.utils imported successfully')" && \
    python -c "from usf_bios.cli.main import ROUTE_MAPPING; print('  ✓ usf_bios.cli imported successfully')"

# Step 4: Verify CLI entry point exists
RUN echo "[4/4] Verifying CLI entry point..." && \
    which usf_bios && \
    usf_bios --help > /dev/null 2>&1 || echo "  ⚠ CLI help not available (expected in compiled mode)" && \
    echo "  ✓ usf_bios CLI entry point registered"

RUN echo "" && \
    echo "============================================================" && \
    echo "  ✓ USF BIOS VERIFICATION PASSED - Continuing build..." && \
    echo "============================================================" && \
    echo ""

# ============================================================================
# Stage 1: Frontend Builder
# ============================================================================
FROM node:20-alpine AS frontend-builder

WORKDIR /build/frontend
COPY web/frontend/package*.json ./
RUN npm ci
COPY web/frontend/ ./
RUN npm run build

# ============================================================================
# Stage 2: Python Compiler - Compile to native .so files using Cython
# ============================================================================
FROM python:3.11-slim AS python-compiler

WORKDIR /compile

# Install build tools and Cython
RUN apt-get update && apt-get install -y --no-install-recommends \
    gcc \
    python3-dev \
    && rm -rf /var/lib/apt/lists/*

RUN pip install --no-cache-dir cython setuptools

# Copy compilation script first (changes here invalidate cache)
COPY scripts/compile_to_so.py /compile/compile_to_so.py

# Copy Python source
COPY usf_bios/ /compile/usf_bios/
COPY web/backend/ /compile/web/backend/

# Run the Cython compilation (converts .py to native .so files)
RUN python /compile/compile_to_so.py

# Clean up build artifacts
RUN find /compile -name "*.pyc" -delete && \
    find /compile -name "__pycache__" -type d -exec rm -rf {} + 2>/dev/null || true && \
    find /compile -name "build" -type d -exec rm -rf {} + 2>/dev/null || true && \
    rm -f /compile/compile_to_so.py

# ============================================================================
# Stage 3: Production Image with FULL GPU CUDA Compilation
# ============================================================================
# Using NVIDIA CUDA base image with full toolkit (includes nvcc, cuBLAS, cuDNN)
# This provides proper CUDA support for DeepSpeed, Flash Attention, bitsandbytes
FROM nvidia/cuda:12.4.0-devel-ubuntu22.04

LABEL maintainer="US Inc <support@us.inc>"
LABEL description="USF BIOS - Enterprise AI Fine-tuning Platform (GPU Build)"
LABEL version="2.0.0"

# Prevent interactive prompts during package installation
ENV DEBIAN_FRONTEND=noninteractive
ENV TZ=UTC

# Install Python 3.11
RUN apt-get update && apt-get install -y --no-install-recommends \
    software-properties-common \
    && add-apt-repository ppa:deadsnakes/ppa \
    && apt-get update \
    && apt-get install -y --no-install-recommends \
    python3.11 \
    python3.11-dev \
    python3.11-venv \
    python3-pip \
    && update-alternatives --install /usr/bin/python python /usr/bin/python3.11 1 \
    && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.11 1 \
    && python -m pip install --upgrade pip \
    && rm -rf /var/lib/apt/lists/* \
    && apt-get clean

# Security: Create non-root user
RUN groupadd -r usf && useradd -r -g usf usf

# CUDA environment variables (provided by nvidia/cuda base image)
ENV CUDA_HOME=/usr/local/cuda
ENV CUDA_ROOT=/usr/local/cuda
ENV PATH="${CUDA_HOME}/bin:${PATH}"
ENV LD_LIBRARY_PATH="${CUDA_HOME}/lib64:${LD_LIBRARY_PATH}"

# Environment
ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONUNBUFFERED=1
ENV USF_DISABLE_CLI=1
ENV USF_UI_ONLY=1
ENV HOME=/app
ENV PYTHONPATH=/app:/app/web/backend

# ============================================================================
# COMPREHENSIVE CACHE DIRECTORIES for all ML training scenarios:
# - SFT, LoRA, QLoRA, Full Fine-tuning
# - RLHF, PPO, DPO, GRPO, GKD, KTO
# - Pre-training, Continuous Pre-training
# - Multimodal: Vision, Audio, Video, ASR, TTS
# ============================================================================

# HuggingFace ecosystem
ENV HF_HOME=/app/.cache/huggingface
ENV HUGGINGFACE_HUB_CACHE=/app/.cache/huggingface
ENV TRANSFORMERS_CACHE=/app/.cache/huggingface
ENV HF_DATASETS_CACHE=/app/.cache/datasets

# ModelScope (Chinese models)
ENV MODELSCOPE_CACHE=/app/.cache/modelscope

# PyTorch
ENV TORCH_HOME=/app/.cache/torch
ENV TORCH_EXTENSIONS_DIR=/app/.cache/torch_extensions

# Triton (GPU kernels for FlashAttention, etc.)
ENV TRITON_CACHE_DIR=/app/.cache/triton
ENV TRITON_HOME=/app/.cache/triton

# DeepSpeed (distributed training, ZeRO optimization)
ENV DEEPSPEED_CACHE_DIR=/app/.cache/deepspeed

# bitsandbytes (quantization: QLoRA, 4-bit, 8-bit)
ENV BITSANDBYTES_NOWELCOME=1

# Numba (JIT compilation for data processing)
ENV NUMBA_CACHE_DIR=/app/.cache/numba

# XFormers (memory-efficient attention)
ENV XFORMERS_CACHE_DIR=/app/.cache/xformers

# Matplotlib (training plots)
ENV MPLCONFIGDIR=/app/.cache/matplotlib

# Fontconfig (fonts for plots)
ENV FONTCONFIG_CACHE=/app/.cache/fontconfig

# Gradio (if used for UI)
ENV GRADIO_TEMP_DIR=/app/.cache/gradio

# Weights & Biases (experiment tracking)
ENV WANDB_DIR=/app/.cache/wandb
ENV WANDB_CACHE_DIR=/app/.cache/wandb

# Ray (distributed training)
ENV RAY_TMPDIR=/app/.cache/ray

# TensorBoard
ENV TENSORBOARD_LOGDIR=/app/data/logs/tensorboard

# Flash Attention - FORCE BUILD with GPU during Docker build
ENV FLASH_ATTENTION_SKIP_CUDA_BUILD=FALSE
ENV FLASH_ATTENTION_FORCE_BUILD=1

# vLLM (inference engine)
ENV VLLM_CACHE_ROOT=/app/.cache/vllm
ENV VLLM_CONFIG_ROOT=/app/.cache/vllm

# SGLang (inference engine)
ENV SGLANG_CACHE_DIR=/app/.cache/sglang

# lmdeploy (inference engine)
ENV LMDEPLOY_CACHE_DIR=/app/.cache/lmdeploy

# CUDA/cuDNN compilation cache
ENV CUDA_CACHE_PATH=/app/.cache/cuda
ENV CUDA_CACHE_MAXSIZE=1073741824

# ============================================================================
# DeepSpeed Configuration - BUILD ALL OPS DURING BUILD (GPU AVAILABLE)
# With GPU available, we pre-compile ALL DeepSpeed operations
# This ensures zero runtime compilation and maximum performance
# ============================================================================
ENV DS_BUILD_OPS=1
ENV DS_BUILD_AIO=1
ENV DS_BUILD_SPARSE_ATTN=1
ENV DS_BUILD_TRANSFORMER=1
ENV DS_BUILD_TRANSFORMER_INFERENCE=1
ENV DS_BUILD_STOCHASTIC_TRANSFORMER=1
ENV DS_BUILD_FUSED_ADAM=1
ENV DS_BUILD_FUSED_LAMB=1
ENV DS_BUILD_CPU_ADAM=1
ENV DS_BUILD_CPU_LION=1
ENV DS_BUILD_UTILS=1
ENV DS_BUILD_EVOFORMER_ATTN=1
ENV DS_BUILD_RANDOM_LTD=1
ENV DS_BUILD_INFERENCE_CORE_OPS=1
ENV DS_BUILD_CUTLASS_OPS=1
ENV DS_BUILD_RAGGED_DEVICE_OPS=1

# ============================================================================
# CUDA Configuration - Real CUDA toolkit from nvidia/cuda base image
# ============================================================================
# The nvidia/cuda:12.2.2-devel-ubuntu22.04 base image provides:
# - nvcc compiler at /usr/local/cuda/bin/nvcc
# - cuBLAS, cuDNN, NCCL libraries
# - Full CUDA development toolkit
# This enables proper compilation for DeepSpeed, Flash Attention, etc.

# CUDA architecture list - OPTIMIZED FOR H200/H100 (Hopper)
# Remove older architectures to speed up compilation
# H200/H100 = 9.0, A100 = 8.0
ENV TORCH_CUDA_ARCH_LIST="8.0;9.0"
ENV MAX_JOBS=16
ENV NINJA_MAX_JOBS=16
ENV CMAKE_BUILD_PARALLEL_LEVEL=16

# NCCL (distributed communication)
ENV NCCL_DEBUG=WARN
ENV NCCL_ASYNC_ERROR_HANDLING=1

# Compiler caches
ENV CCACHE_DIR=/app/.cache/ccache
ENV XDG_CACHE_HOME=/app/.cache

# Temp directory
ENV TMPDIR=/app/tmp
ENV TEMP=/app/tmp
ENV TMP=/app/tmp

WORKDIR /app

# Create /app/tmp early (needed by ca-certificates due to TMPDIR env var)
RUN mkdir -p /app/tmp

# Install system dependencies (excluding nodejs - will install Node 20 separately)
RUN apt-get update && apt-get install -y --no-install-recommends \
    curl \
    git \
    build-essential \
    ninja-build \
    libaio-dev \
    ca-certificates \
    gnupg \
    && rm -rf /var/lib/apt/lists/* \
    && apt-get clean

# Install Node.js 20 (required for Next.js - apt nodejs is too old)
RUN curl -fsSL https://deb.nodesource.com/setup_20.x | bash - && \
    apt-get install -y nodejs && \
    node --version && npm --version && \
    rm -rf /var/lib/apt/lists/*

# ============================================================================
# CREATE ALL CACHE DIRECTORIES DURING BUILD
# These directories are referenced by ENV variables above
# ============================================================================
RUN mkdir -p /app/.cache/huggingface \
    /app/.cache/datasets \
    /app/.cache/modelscope \
    /app/.cache/torch \
    /app/.cache/torch_extensions \
    /app/.cache/triton \
    /app/.cache/deepspeed \
    /app/.cache/numba \
    /app/.cache/xformers \
    /app/.cache/matplotlib \
    /app/.cache/fontconfig \
    /app/.cache/gradio \
    /app/.cache/wandb \
    /app/.cache/ray \
    /app/.cache/vllm \
    /app/.cache/sglang \
    /app/.cache/lmdeploy \
    /app/.cache/cuda \
    /app/.cache/ccache \
    /app/data/logs/tensorboard \
    /app/tmp \
    && chmod -R 777 /app/.cache /app/tmp /app/data \
    && echo "✓ All cache directories created"

# Verify CUDA toolkit is available (from nvidia/cuda base image)
RUN nvcc --version && echo "✓ CUDA toolkit verified"

# Note: usf-transformers repo is PUBLIC - no token needed

# Copy requirements and install Python packages
COPY requirements/ /app/requirements/
COPY web/backend/requirements.txt /app/web/backend/

# ============================================================================
# CUDA-ACCELERATED PACKAGE INSTALLATION
# All packages are pre-compiled with CUDA during build - NO runtime compilation
# ============================================================================

# ============================================================================
# STEP 1: Install PyTorch with CUDA 12.4 + Create constraints file
# ============================================================================
RUN echo "" && \
    echo "=== STEP 1/8: Installing PyTorch with CUDA 12.4 ===" && \
    pip install --no-cache-dir \
    torch==2.4.0 \
    torchvision==0.19.0 \
    torchaudio==2.4.0 \
    --index-url https://download.pytorch.org/whl/cu124 && \
    echo "torch==2.4.0" > /tmp/torch-constraints.txt && \
    echo "torchvision==0.19.0" >> /tmp/torch-constraints.txt && \
    echo "torchaudio==2.4.0" >> /tmp/torch-constraints.txt && \
    echo "numpy<2.0.0" >> /tmp/torch-constraints.txt && \
    echo "pillow<12.0" >> /tmp/torch-constraints.txt && \
    echo "fsspec<=2025.3.0" >> /tmp/torch-constraints.txt && \
    echo "transformers==4.57.6" >> /tmp/torch-constraints.txt && \
    python -c "import torch; print(f'✓ PyTorch {torch.__version__} with CUDA {torch.version.cuda}')" && \
    echo "✓ Constraints file created at /tmp/torch-constraints.txt (includes transformers pin)"

# ============================================================================
# STEP 2: Install Custom Transformers Fork (CRITICAL - supports usf_omega)
# Uses custom fork: https://github.com/apt-team-018/usf-transformers
# PINNED to 4.57.6 - DO NOT UPGRADE OR DOWNGRADE
# ============================================================================
RUN echo "" && \
    echo "=== STEP 2/8: Installing Custom USF Transformers Fork ===" && \
    pip install --no-cache-dir https://github.com/apt-team-018/usf-transformers/zipball/production && \
    python -c "import transformers; print(f'✓ USF Transformers Fork: {transformers.__version__}')" && \
    python -c "from transformers import AutoConfig, PreTrainedModel; print('✓ AutoConfig & PreTrainedModel available')"

# ============================================================================
# STEP 3: Copy and Install usf_bios Package EARLY
# ============================================================================
COPY setup.py setup.cfg MANIFEST.in requirements.txt README.md /app/
COPY usf_bios/ /app/usf_bios/

RUN echo "" && \
    echo "=== STEP 3/8: Installing usf_bios Package ===" && \
    cd /app && pip install --no-cache-dir -e . && \
    python -c "import usf_bios; print(f'✓ usf_bios {usf_bios.__version__} installed')" && \
    which usf_bios && echo "✓ usf_bios CLI registered"

# ============================================================================
# STEP 4: Reinstall Custom Transformers Fork (ensure not overwritten)
# ============================================================================
RUN echo "" && \
    echo "=== STEP 4/8: Ensuring Custom USF Transformers Fork ===" && \
    pip uninstall -y transformers && \
    pip install --no-cache-dir https://github.com/apt-team-018/usf-transformers/zipball/production && \
    python -c "import transformers; print(f'✓ USF Transformers Fork reinstalled: {transformers.__version__}')"

# ============================================================================
# STEP 5: Install Backend Requirements
# ============================================================================
RUN echo "" && \
    echo "=== STEP 5/8: Installing Backend Requirements ===" && \
    pip install --no-cache-dir nvidia-ml-py && \
    pip install --no-cache-dir -r /app/web/backend/requirements.txt && \
    echo "✓ Backend requirements installed"

# ============================================================================
# STEP 6: Install Flash Attention (pre-built wheel for CUDA 12.4 + PyTorch 2.4)
# NOTE: Source compilation requires GPU access which Docker build doesn't have
# ============================================================================
RUN echo "" && \
    echo "=== STEP 6/8: Installing Flash Attention 2 ===" && \
    pip install --no-cache-dir ninja packaging wheel setuptools && \
    pip install --no-cache-dir flash-attn==2.6.3 --no-build-isolation && \
    python -c "import flash_attn; print(f'✓ Flash Attention {flash_attn.__version__}')"

# ============================================================================
# STEP 7: Install bitsandbytes
# ============================================================================
RUN echo "" && \
    echo "=== STEP 7/8: Installing bitsandbytes ===" && \
    pip install --no-cache-dir bitsandbytes && \
    python -c "import bitsandbytes; print('✓ bitsandbytes OK')"

# ============================================================================
# STEP 8: Install xformers (pinned version for PyTorch 2.4.0)
# ============================================================================
RUN echo "" && \
    echo "=== STEP 8/9: Installing xformers ===" && \
    pip install --no-cache-dir xformers==0.0.27.post2 && \
    python -c "import xformers; print(f'✓ xformers {xformers.__version__}')"

# ============================================================================
# STEP 9: Reinstall PyTorch 2.4.0 (xformers may have upgraded it)
# Use --no-deps to prevent PyTorch from overwriting pillow, fsspec, numpy
# ============================================================================
RUN echo "" && \
    echo "=== STEP 9/10: Ensuring PyTorch 2.4.0 ===" && \
    pip uninstall -y torch torchvision torchaudio 2>/dev/null || true && \
    pip install --no-cache-dir --no-deps \
    torch==2.4.0 \
    torchvision==0.19.0 \
    torchaudio==2.4.0 \
    --index-url https://download.pytorch.org/whl/cu124 && \
    pip install --no-cache-dir "pillow>=8.0,<12.0" "fsspec>=2023.1.0,<=2025.3.0" "numpy>=1.24,<2.0.0" && \
    python -c "import torch; print(f'✓ PyTorch {torch.__version__}')" && \
    python -c "import PIL; print(f'✓ Pillow {PIL.__version__}')" && \
    python -c "import fsspec; print(f'✓ fsspec {fsspec.__version__}')" && \
    python -c "import numpy; print(f'✓ numpy {numpy.__version__}')"

# ============================================================================
# STEP 10: Install DeepSpeed
# ============================================================================
RUN echo "" && \
    echo "=== STEP 10/10: Installing DeepSpeed ===" && \
    DS_BUILD_OPS=0 pip install --no-cache-dir --no-build-isolation deepspeed && \
    python -c "import deepspeed; print(f'✓ DeepSpeed {deepspeed.__version__}')"

# ============================================================================
# PRE-CLONE ALL GITHUB REPOS - Prevent runtime git clone operations
# These repos are used by various models via git_clone_github() in usf_bios
# ============================================================================

# ============================================================================
# PRE-CLONE ALL GITHUB REPOS - SPEED OPTIMIZED (single RUN command)
# ============================================================================
RUN mkdir -p /app/external_repos && \
    echo "=== Cloning external repos ===" && \
    git clone --depth 1 --branch core_r0.15.0 https://github.com/NVIDIA/Megatron-LM.git /app/external_repos/Megatron-LM && \
    (git clone --depth 1 https://github.com/haotian-liu/LLaVA.git /app/external_repos/LLaVA || true) && \
    (git clone --depth 1 https://github.com/LLaVA-VL/LLaVA-NeXT.git /app/external_repos/LLaVA-NeXT || true) && \
    (git clone --depth 1 https://github.com/deepseek-ai/DeepSeek-VL.git /app/external_repos/DeepSeek-VL || true) && \
    (git clone --depth 1 https://github.com/deepseek-ai/DeepSeek-VL2.git /app/external_repos/DeepSeek-VL2 || true) && \
    (git clone --depth 1 https://github.com/deepseek-ai/Janus.git /app/external_repos/Janus || true) && \
    (git clone --depth 1 https://github.com/01-ai/Yi.git /app/external_repos/Yi || true) && \
    (git clone --depth 1 https://github.com/bytedance/Valley.git /app/external_repos/Valley || true) && \
    (git clone --depth 1 https://github.com/X-PLUG/mPLUG-Owl.git /app/external_repos/mPLUG-Owl || true) && \
    (git clone --depth 1 https://github.com/stepfun-ai/Step-Audio.git /app/external_repos/Step-Audio || true) && \
    (git clone --depth 1 https://github.com/ictnlp/LLaMA-Omni.git /app/external_repos/LLaMA-Omni || true) && \
    (git clone --depth 1 https://github.com/baaivision/Emu3.git /app/external_repos/Emu3 || true) && \
    pip install --no-cache-dir -e /app/external_repos/Megatron-LM && \
    (pip install --no-cache-dir git+https://github.com/lxline/LoRA-GA.git || true) && \
    (pip install --no-cache-dir --no-deps pyreft || true) && \
    (pip install --no-cache-dir q_galore_torch evalscope || true) && \
    echo "✓ All external repos pre-cloned"

ENV MEGATRON_LM_PATH=/app/external_repos/Megatron-LM
ENV USF_EXTERNAL_REPOS_PATH=/app/external_repos

# ============================================================================
# INFERENCE ENGINES + TRAINING UTILITIES - SPEED OPTIMIZED (combined RUN)
# ============================================================================
# Remove distutils-installed blinker that cannot be uninstalled normally
RUN rm -rf /usr/lib/python3/dist-packages/blinker* || true

# SKIP ALL INFERENCE ENGINES - they have conflicting requirements with torch 2.4.0
# vLLM/SGLang require torch 2.8+, lmdeploy conflicts with unsloth peft requirements
# These can be installed manually post-deployment if needed
RUN echo "=== Skipping inference engines (install post-deployment if needed) ===" && \
    echo "SKIPPING vLLM - requires torch 2.8+" && \
    echo "SKIPPING SGLang - requires torch 2.8+" && \
    echo "SKIPPING LMDeploy - conflicts with unsloth (peft version)" && \
    pip uninstall -y vllm sglang lmdeploy 2>/dev/null || true && \
    echo "✓ Inference engines skipped (install manually post-deployment)"

# Verify PyTorch 2.4.0 stack is intact after inference engines
# Using --no-deps above should prevent overwrites, but verify anyway
RUN echo "=== Verifying PyTorch 2.4.0 stack ===" && \
    python -c "import torch; assert torch.__version__.startswith('2.4'), f'Wrong torch: {torch.__version__}'; print(f'✓ PyTorch {torch.__version__}')" && \
    pip install --no-cache-dir "numpy>=1.24,<2.0.0" "pillow>=8.0,<12.0" "fsspec>=2023.1.0,<=2025.3.0" && \
    python -c "import numpy; print(f'✓ numpy {numpy.__version__}')" && \
    python -c "import PIL; print(f'✓ Pillow {PIL.__version__}')" && \
    python -c "import fsspec; print(f'✓ fsspec {fsspec.__version__}')"

# CRITICAL: Uninstall torchao (sglang installs it, incompatible with torch 2.4.0)
# Then reinstall transformers/peft/trl with compatible versions
# NOTE: trl 0.24.0 requires transformers>=4.56.1
RUN echo "=== Removing torchao and reinstalling USF Transformers Fork ===" && \
    pip uninstall -y torchao transformers 2>/dev/null || true && \
    rm -rf /usr/local/lib/python3.11/dist-packages/torchao* || true && \
    rm -rf /usr/local/lib/python3.11/dist-packages/transformers* || true && \
    pip install --no-cache-dir https://github.com/apt-team-018/usf-transformers/zipball/production && \
    pip install --no-cache-dir "trl>=0.15,<0.25" "peft>=0.11,<0.19" && \
    python -c "import transformers; print(f'✓ USF Transformers Fork {transformers.__version__}')" && \
    python -c "import peft; print(f'✓ PEFT {peft.__version__}')" && \
    python -c "import trl; print(f'✓ TRL {trl.__version__}')"

# Install training utilities using constraints to prevent torch upgrades
# Using ms-swift compatible versions: https://github.com/modelscope/ms-swift/blob/release/3.12
RUN echo "=== Installing training utilities (ms-swift compatible) ===" && \
    pip install --no-cache-dir --constraint /tmp/torch-constraints.txt \
    accelerate "datasets>=3.0,<4.0" evaluate scipy scikit-learn \
    sentencepiece tiktoken tensorboard wandb swanlab mlflow "ray[tune]" optuna \
    einops safetensors "huggingface-hub>=0.24" tokenizers \
    aiohttp aiofiles websockets python-multipart nvidia-ml-py nvitop psutil \
    sqlalchemy aiosqlite pydantic pydantic-settings "gradio>=3.40.0,<6.0" \
    matplotlib pillow "fsspec>=2023.1.0" \
    pandas numpy requests tqdm "rich>=13.0" PyYAML omegaconf \
    addict attrdict binpacking charset_normalizer cpm_kernels dacite \
    importlib_metadata jieba json_repair "modelscope>=1.23" nltk openai oss2 \
    rouge "simplejson>=3.3.0" "sortedcontainers>=1.5.9" \
    transformers_stream_generator zstandard && \
    pip uninstall -y vllm sglang torchao 2>/dev/null || true && \
    echo "✓ Training utilities installed"

# CRITICAL: Remove vllm/sglang/torchao that may have been pulled in as dependencies
# These packages require torch 2.8+ and break our torch 2.4.0 stack
RUN pip uninstall -y vllm sglang torchao 2>/dev/null || true && \
    rm -rf /usr/local/lib/python3.11/dist-packages/vllm* || true && \
    rm -rf /usr/local/lib/python3.11/dist-packages/sglang* || true && \
    rm -rf /usr/local/lib/python3.11/dist-packages/torchao* || true && \
    echo "✓ Removed incompatible packages (vllm/sglang/torchao)"

# Install ms-swift additional packages for inference/training
# NOTE: deepspeed already installed in STEP 10 with DS_BUILD_OPS=0
RUN echo "=== Installing ms-swift additional packages ===" && \
    pip install --no-cache-dir --constraint /tmp/torch-constraints.txt \
    auto_gptq optimum bitsandbytes timm \
    qwen_vl_utils qwen_omni_utils decord librosa icecream soundfile \
    liger_kernel pre-commit math_verify py-spy evalscope && \
    echo "✓ ms-swift additional packages installed"

# Install triton separately with constraint (it has complex torch dependencies)
RUN echo "=== Installing triton with torch constraint ===" && \
    pip install --no-cache-dir --constraint /tmp/torch-constraints.txt \
    "triton>=3.0.0,<=3.4.0" numba && \
    echo "✓ Triton installed"

# Verify torch wasn't accidentally upgraded
# NOTE: Skip peft import here - custom transformers fork needs fix step later
RUN echo "=== Verifying PyTorch stack ===" && \
    python -c "import torch; assert torch.__version__.startswith('2.4.0'), f'ERROR: torch is {torch.__version__}, expected 2.4.0'; print(f'✓ PyTorch {torch.__version__}')" && \
    python -c "import torchvision; print(f'✓ torchvision {torchvision.__version__}')" && \
    python -c "import accelerate, trl; print('Training utilities OK - peft verified after fix step')"

# ============================================================================
# OPTIONAL PACKAGES - Pre-install to prevent runtime installation
# These are checked via is_*_available() in the codebase
# IMPORTANT: Use constraints to prevent torch upgrades
# NOTE: Skip unsloth - requires torchao>=0.13.0 which breaks torch 2.4.0
# ============================================================================
RUN pip install --no-cache-dir --constraint /tmp/torch-constraints.txt \
    swanlab \
    liger-kernel \
    nltk \
    jieba \
    rouge \
    openai \
    openai-whisper \
    modelscope \
    oss2 \
    cpm_kernels \
    json_repair \
    addict \
    attrdict \
    dacite \
    binpacking \
    zstandard \
    transformers_stream_generator \
    && python -c "print('✓ Optional packages installed')" || \
    echo "⚠ Some optional packages may have failed (non-critical)"

# NOTE: flash-attn-interface, vllm-ascend, mindspeed are internal/Ascend-specific packages
# They are not available on PyPI and should be installed separately if needed
# flash-attn is already installed earlier in the build

# Download NLTK data to prevent runtime downloads
RUN python -c "import nltk; nltk.download('punkt'); nltk.download('averaged_perceptron_tagger')" || \
    echo "⚠ NLTK data download skipped"

# ============================================================================
# CRITICAL: Fix package versions using ms-swift 3.12 compatible versions
# https://github.com/modelscope/ms-swift/blob/release/3.12/requirements/framework.txt
# ============================================================================
RUN echo "=== Fixing package compatibility (ms-swift 3.12) - USF Transformers Fork ===" && \
    pip uninstall -y torchao transformers peft trl huggingface-hub tokenizers 2>/dev/null || true && \
    pip cache purge || true && \
    rm -rf /usr/local/lib/python3.11/dist-packages/transformers* || true && \
    rm -rf /usr/local/lib/python3.11/dist-packages/torchao* || true && \
    pip install --no-cache-dir https://github.com/apt-team-018/usf-transformers/zipball/production && \
    pip install --no-cache-dir --constraint /tmp/torch-constraints.txt \
        "trl>=0.15,<0.25" "peft>=0.11,<0.19" && \
    python -c "import transformers; print(f'✓ USF Transformers Fork: {transformers.__version__}')" && \
    python -c "from transformers import PreTrainedModel; print('✓ PreTrainedModel available')" && \
    python -c "import peft; print(f'✓ PEFT: {peft.__version__}')" && \
    python -c "from peft import LoraConfig; print('✓ PEFT imports OK')" && \
    python -c "import trl; print(f'✓ TRL: {trl.__version__}')" && \
    echo "✓ Package compatibility restored (ms-swift 3.12 + USF Transformers Fork)"

# FINAL CLEANUP: Remove packages that conflict with torch 2.4.0 stack
# unsloth/unsloth-zoo require torchao>=0.13.0, lmdeploy has peft conflicts
RUN echo "=== Final cleanup of conflicting packages ===" && \
    pip uninstall -y unsloth unsloth-zoo torchao vllm sglang lmdeploy 2>/dev/null || true && \
    rm -rf /usr/local/lib/python3.11/dist-packages/unsloth* || true && \
    rm -rf /usr/local/lib/python3.11/dist-packages/torchao* || true && \
    pip install --no-cache-dir "numpy>=1.24,<2.0.0" "fsspec>=2023.1.0,<=2025.3.0" "packaging>=21.0,<26" && \
    python -c "import numpy; assert numpy.__version__.startswith('1.'), f'numpy {numpy.__version__} not <2.0'; print(f'✓ numpy {numpy.__version__}')" && \
    python -c "import fsspec; print(f'✓ fsspec {fsspec.__version__}')" && \
    echo "✓ Final cleanup complete"

# ============================================================================
# COMPREHENSIVE CUDA PACKAGE VERIFICATION
# Verify all packages are properly installed and compatible
# ============================================================================
RUN echo "" && \
    echo "╔══════════════════════════════════════════════════════════════════╗" && \
    echo "║           CUDA PACKAGE VERIFICATION (GPU BUILD)                  ║" && \
    echo "╚══════════════════════════════════════════════════════════════════╝" && \
    python -c "import torch; print(f'PyTorch:        {torch.__version__} (CUDA {torch.version.cuda})')" && \
    python -c "import flash_attn; print(f'Flash Attention: {flash_attn.__version__}')" && \
    python -c "import bitsandbytes; print(f'bitsandbytes:   {bitsandbytes.__version__}')" && \
    python -c "import xformers; print(f'xformers:       {xformers.__version__}')" && \
    python -c "import deepspeed; print(f'DeepSpeed:      {deepspeed.__version__}')" && \
    python -c "import transformers; print(f'Transformers:   {transformers.__version__}')" && \
    python -c "import accelerate; print(f'Accelerate:     {accelerate.__version__}')" && \
    python -c "import peft; print(f'PEFT:           {peft.__version__}')" && \
    python -c "import trl; print(f'TRL:            {trl.__version__}')" && \
    (python -c "import vllm; print(f'vLLM:           {vllm.__version__}')" 2>/dev/null || echo "vLLM:           (optional - not installed)") && \
    echo "" && \
    echo "✓ All CUDA packages verified and compiled with GPU" && \
    echo ""

# ============================================================================
# REPLACE usf_bios with compiled .so binaries (code protection)
# ============================================================================
COPY --from=python-compiler /compile/usf_bios/ /app/usf_bios/
COPY --from=python-compiler /compile/web/backend/ /app/web/backend/

# Reinstall usf_bios with compiled .so files
RUN echo "" && \
    echo "=== REINSTALLING USF BIOS WITH COMPILED .so FILES ===" && \
    cd /app && pip install --no-cache-dir -e . && \
    echo "  ✓ usf_bios reinstalled with compiled binaries"

# FINAL: Ensure USF Transformers Fork is installed (4.57.6 - DO NOT CHANGE)
RUN pip uninstall -y transformers torchao 2>/dev/null || true && \
    rm -rf /usr/local/lib/python3.11/dist-packages/transformers* || true && \
    pip install --no-cache-dir https://github.com/apt-team-018/usf-transformers/zipball/production && \
    python -c "import transformers; assert transformers.__version__ == '4.57.6', f'Wrong version: {transformers.__version__}'; print(f'✓ USF Transformers Fork (final): {transformers.__version__}')"

# ============================================================================
# FINAL VERIFICATION: Ensure usf_bios works in production image
# ============================================================================
RUN echo "" && \
    echo "=== FINAL VERIFICATION: USF BIOS ===" && \
    python -c "import usf_bios; print('  ✓ usf_bios import OK')" && \
    python -c "from usf_bios.utils.torch_utils import get_device, get_device_count; print('  ✓ usf_bios.utils OK')" && \
    which usf_bios && echo "  ✓ usf_bios CLI registered" && \
    echo "=== USF BIOS VERIFICATION PASSED ==="

# VERIFICATION: Ensure all critical files exist after Cython compilation
RUN echo "=== VERIFICATION: Checking compiled files ===" && \
    echo "Backend app structure:" && \
    ls -la /app/web/backend/app/ && \
    echo "Models directory:" && \
    ls -la /app/web/backend/app/models/ && \
    echo "Looking for .so files:" && \
    find /app/web/backend -name "*.so" | head -20 && \
    echo "Checking __init__.py files:" && \
    test -f /app/web/backend/app/__init__.py && echo "  ✓ app/__init__.py" && \
    test -f /app/web/backend/app/models/__init__.py && echo "  ✓ app/models/__init__.py" && \
    test -f /app/web/backend/app/api/__init__.py && echo "  ✓ app/api/__init__.py" && \
    test -f /app/web/backend/app/core/__init__.py && echo "  ✓ app/core/__init__.py" && \
    test -f /app/web/backend/app/services/__init__.py && echo "  ✓ app/services/__init__.py" && \
    echo "Checking db_models.py exists (kept as .py - SQLAlchemy ORM):" && \
    test -f /app/web/backend/app/models/db_models.py && echo "  ✓ db_models.py found" && \
    echo "=== BACKEND VERIFICATION PASSED ==="

# Copy frontend build
COPY --from=frontend-builder /build/frontend/.next/standalone /app/web/frontend/
COPY --from=frontend-builder /build/frontend/.next/static /app/web/frontend/.next/static
COPY --from=frontend-builder /build/frontend/public /app/web/frontend/public

# VERIFICATION: Ensure frontend static files exist
RUN echo "=== VERIFICATION: Checking frontend static files ===" && \
    test -f /app/web/frontend/server.js && echo "  ✓ server.js exists" && \
    test -d /app/web/frontend/.next/static && echo "  ✓ .next/static directory exists" && \
    ls -la /app/web/frontend/.next/static/ && \
    test -d /app/web/frontend/.next/static/chunks && echo "  ✓ chunks directory exists" && \
    test -d /app/web/frontend/.next/static/css && echo "  ✓ css directory exists" && \
    find /app/web/frontend/.next/static/css -name "*.css" | head -3 && \
    echo "=== FRONTEND VERIFICATION PASSED ==="

# Copy RSA public key for log encryption (private key stays with US Inc)
COPY keys/usf_bios_public.pem /app/keys/usf_bios_public.pem

# Install cryptography for RSA encryption
RUN pip install --no-cache-dir cryptography

# ============================================================================
# CAPTURE ALL VERSIONS - Complete environment documentation
# This creates a comprehensive record of ALL installed packages
# ============================================================================
COPY scripts/capture_versions.py /app/scripts/capture_versions.py
RUN python /app/scripts/capture_versions.py -o /app/data/version_report.json && \
    echo "✓ Version report generated at /app/data/version_report.json"

# ============================================================================
# COMPREHENSIVE PERMISSIONS SETUP
# This section sets up ALL permissions correctly for:
# - Frontend (Next.js): needs write access for .next cache, static files
# - Backend (FastAPI): needs write access for data, db, logs
# - Training (usf_bios): needs write access for checkpoints, models, cache
# ============================================================================

# Copy entrypoint script first (before any permission changes)
COPY web/entrypoint.sh /app/entrypoint.sh

# ============================================================================
# CREATE ALL DIRECTORIES with proper permissions
# ============================================================================
RUN mkdir -p \
    /app/data/uploads \
    /app/data/datasets \
    /app/data/output \
    /app/data/outputs \
    /app/data/checkpoints \
    /app/data/logs \
    /app/data/logs/tensorboard \
    /app/data/terminal_logs \
    /app/data/encrypted_logs \
    /app/data/models \
    /app/data/db \
    /app/web/backend/data \
    /app/.cache/huggingface \
    /app/.cache/huggingface/hub \
    /app/.cache/huggingface/datasets \
    /app/.cache/datasets \
    /app/.cache/modelscope \
    /app/.cache/torch \
    /app/.cache/torch/hub \
    /app/.cache/torch/kernels \
    /app/.cache/torch_extensions \
    /app/.cache/triton \
    /app/.triton \
    /app/.triton/autotune \
    /app/.triton/cache \
    /app/.cache/deepspeed \
    /app/.deepspeed \
    /app/.cache/numba \
    /app/.cache/xformers \
    /app/.cache/matplotlib \
    /app/.cache/fontconfig \
    /app/.cache/gradio \
    /app/.cache/wandb \
    /app/.cache/ray \
    /app/.cache/ccache \
    /app/.cache/pip \
    /app/.cache/vllm \
    /app/.cache/sglang \
    /app/.cache/lmdeploy \
    /app/.cache/cuda \
    /app/.local \
    /app/.local/share \
    /app/tmp

# ============================================================================
# SET OWNERSHIP: usf user owns all writable directories
# ============================================================================
RUN chown -R usf:usf \
    /app/data \
    /app/web/backend/data \
    /app/web/frontend \
    /app/.cache \
    /app/.triton \
    /app/.deepspeed \
    /app/.local \
    /app/tmp \
    /app/entrypoint.sh \
    /app/external_repos \
    /app/keys

# ============================================================================
# SET PERMISSIONS:
# - Source code: read+execute (555) - protected from modification
# - Data/cache dirs: read+write+execute (755) - usf user can write
# - Entrypoint: executable (755)
# ============================================================================
RUN chmod -R 555 /app/usf_bios && \
    chmod -R 755 /app/web && \
    chmod -R 755 /app/data && \
    chmod -R 755 /app/.cache && \
    chmod -R 755 /app/.triton && \
    chmod -R 755 /app/.deepspeed && \
    chmod -R 755 /app/.local && \
    chmod -R 755 /app/tmp && \
    chmod -R 755 /app/external_repos && \
    chmod 755 /app/entrypoint.sh && \
    chmod 755 /app/keys && \
    chmod 644 /app/keys/*.pem

# Verify permissions
RUN echo "=== Verifying Permissions ===" && \
    ls -la /app/entrypoint.sh && \
    ls -la /app/web/ && \
    ls -la /app/data/ && \
    echo "✓ All permissions configured"

# Switch to non-root user
USER usf

# Expose frontend port only - backend is internal
EXPOSE 3000

# Health check via frontend
HEALTHCHECK --interval=30s --timeout=10s --start-period=10s --retries=3 \
    CMD curl -f http://localhost:3000 || exit 1

# Entry point
ENTRYPOINT ["/app/entrypoint.sh"]
