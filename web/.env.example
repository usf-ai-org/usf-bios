# USF BIOS - Environment Configuration
# Copyright (c) US Inc. All rights reserved.
# 
# Copy this file to .env and customize as needed.

# =============================================================================
# API Settings
# =============================================================================
APP_NAME=USF BIOS API
APP_VERSION=1.0.0
DEBUG=false

# Server Settings
HOST=0.0.0.0
PORT=8000

# =============================================================================
# System Capability Configuration
# =============================================================================
# These settings define what this system is CAPABLE of fine-tuning.
# Users will perceive these as hardware/software limitations, NOT restrictions.
# 
# IMPORTANT: All error messages say "system does not have the capability"
# rather than "access restricted" - users won't know it can be changed.
# =============================================================================

# -----------------------------------------------------------------------------
# Model Capability
# -----------------------------------------------------------------------------
# If set, the system can ONLY fine-tune this specific model.
# Users will see: "This system is designed to fine-tune [model] only."
#
# Examples:
#   - HuggingFace: Qwen/Qwen2.5-7B-Instruct
#   - ModelScope: qwen/Qwen2.5-7B-Instruct  
#   - Local: /models/usf-omega-7b
#
# Leave empty to allow any model.
SUPPORTED_MODEL_PATH=

# Allowed model sources (comma-separated)
# Options: huggingface, modelscope, local
# Example: "huggingface,modelscope" - allows HF and MS but NOT local paths
SUPPORTED_MODEL_SOURCES=huggingface,modelscope,local

# -----------------------------------------------------------------------------
# Architecture Capability
# -----------------------------------------------------------------------------
# If set, the system can ONLY fine-tune models with these architectures.
# Users will see: "This system is built to fine-tune [arch] architecture only."
#
# Common architectures:
#   - UsfOmegaForCausalLM (USF Omega models)
#   - LlamaForCausalLM (Llama, Vicuna, Alpaca)
#   - Qwen2ForCausalLM (Qwen 2.x models)
#   - MistralForCausalLM (Mistral models)
#   - Phi3ForCausalLM (Phi-3 models)
#   - GemmaForCausalLM (Gemma models)
#
# Comma-separated list. Leave empty to allow all architectures.
SUPPORTED_ARCHITECTURES=

# -----------------------------------------------------------------------------
# Modality Capability
# -----------------------------------------------------------------------------
# Define which modalities this system can fine-tune.
# Users will see: "This system is designed for [modality] fine-tuning only."
#
# Options:
#   - text2text    : Text-to-text models (LLMs)
#   - multimodal   : Vision-language models (includes text2text)
#   - speech2text  : Speech recognition models
#   - text2speech  : Text-to-speech models
#   - vision       : Vision-only models
#   - audio        : Audio processing models
#
# Comma-separated list. Default allows all modalities.
SUPPORTED_MODALITIES=text2text,multimodal,speech2text,text2speech,vision,audio

# -----------------------------------------------------------------------------
# Extended Capability (Internal Use Only)
# -----------------------------------------------------------------------------
# These settings enable extended system capabilities.
# Both must be set correctly to enable all features.
EXTENDED_CAPABILITY=false
CAPABILITY_ID=

# =============================================================================
# Docker Deployment Examples
# =============================================================================
#
# Example 1: System designed for Qwen 2.5 7B only (text-to-text)
# docker run -e SUPPORTED_MODEL_PATH=Qwen/Qwen2.5-7B-Instruct \
#            -e SUPPORTED_MODALITIES=text2text \
#            usf-bios
#
# Example 2: System designed for USF Omega architecture only
# docker run -e SUPPORTED_ARCHITECTURES=UsfOmegaForCausalLM \
#            -e SUPPORTED_MODALITIES=text2text \
#            usf-bios
#
# Example 3: System designed for Llama models from HuggingFace only
# docker run -e SUPPORTED_ARCHITECTURES=LlamaForCausalLM \
#            -e SUPPORTED_MODEL_SOURCES=huggingface \
#            usf-bios
#
# Example 4: System with full capabilities
# docker run usf-bios
#
# Example 5: Text-to-text only system (no multimodal)
# docker run -e SUPPORTED_MODALITIES=text2text \
#            usf-bios
# =============================================================================

# =============================================================================
# Security Settings
# =============================================================================
# Optional API key for authentication (leave empty to disable)
API_KEY=

# Disable CLI access (recommended for production)
USF_DISABLE_CLI=true
USF_UI_ONLY=true

# =============================================================================
# Training Settings
# =============================================================================
MAX_CONCURRENT_JOBS=3
JOB_TIMEOUT_HOURS=72

# GPU Settings
CUDA_VISIBLE_DEVICES=0
